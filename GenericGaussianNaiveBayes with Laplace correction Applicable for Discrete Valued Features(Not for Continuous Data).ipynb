{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train,Y_train):\n",
    "    #First i want to make a dictionary\n",
    "    data_dict={}\n",
    "    #Then now i want to Find all the unique classes in my target for instance here in my data 0,1,2 are my classes...\n",
    "    #Now let me find all unique classes this act as my keys for further processing....\n",
    "    unique_target_names=np.unique(Y_train)\n",
    "    for i in unique_target_names:\n",
    "        data_dict[i]={}   #----->This results data_dict[0]--->{}\n",
    "        #Now i want to find all the feature names in my datasets....\n",
    "        #print(X_train.columns)------>It gives the Range Index of start and end value which is diificult to iterate..\n",
    "        filter_X_train=X_train[Y_train==i]\n",
    "        data_dict[i]['total_class']=len(filter_X_train)\n",
    "        for feature in X_train.columns:\n",
    "            unique_column_values=np.unique(X_train[feature])\n",
    "            #print(\"Unique_column_values are {}\".format(unique_column_values))\n",
    "            #print(\"Guys this is for the unique_column {}\".format(i))\n",
    "            data_dict[i][feature]={}\n",
    "            \n",
    "            for unique_value in unique_column_values:\n",
    "                \n",
    "                count=(filter_X_train[feature]==unique_value)\n",
    "                count=(filter_X_train[feature][count].count())\n",
    "                #print(count)\n",
    "                data_dict[i][feature][unique_value]=count\n",
    "              #  print(\"I want to give the count of each different values in the columnn {} and count is {}\".format(unique_value,count))\n",
    "   \n",
    "    data_dict['total_training']=len(Y_train)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_probability_class(data_dict,datapoint):\n",
    "    #Now i want to find the best class to do that i want to find the probabilities over all classes and find the highest probability class..\n",
    "    best_class=-100\n",
    "    best_probab=-1000\n",
    "    find_all_target_classes=data_dict.keys()\n",
    "    #print(find_all_target_classes)\n",
    "    output=1\n",
    "    #Now i want to apply the bayes theorem i.e p(y/x)=p(x/y)*p(y)/p(x).. here i ignore p(x) because in testing there is highprobabilty that i wont see the point\n",
    "    for i in find_all_target_classes:\n",
    "        output=1\n",
    "        count=0\n",
    "        if(i is 'total_training'):\n",
    "            continue\n",
    "        output=output*data_dict[i]['total_class']/data_dict['total_training']\n",
    "        \n",
    "        feature_keys=data_dict[i].keys()\n",
    "        for feature in feature_keys:\n",
    "            if(feature is 'total_class'):\n",
    "                continue\n",
    "            xd=len(data_dict[i][feature].keys())\n",
    "            ratio=(data_dict[i][feature][datapoint[feature]]+1)/(data_dict[i]['total_class']+xd)\n",
    "            output=output*ratio\n",
    "        #print(\"The output for class {} is {}\".format(i,output))  \n",
    "        if(output>best_probab):\n",
    "            best_probab=output\n",
    "            best_class=i\n",
    "            count=count+1\n",
    "            \n",
    "    #print(\"Finally The best class is {} and probabilty now is:{} and count is {}\".format(best_class,best_probab,count))\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_dict,X_test):\n",
    "    predict_class_lst=[]\n",
    "    for i in range(len(X_test)):\n",
    "        datapoint=X_test.iloc[i]\n",
    "        present_class=find_best_probability_class(data_dict,datapoint)\n",
    "        predict_class_lst.append(present_class)\n",
    "    return predict_class_lst\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(lst,mean_value):\n",
    "    for i in range(len(lst)):\n",
    "        if(lst[i]<0.25*mean_value):\n",
    "            lst[i]=0\n",
    "        elif(lst[i]>0.25*mean_value and lst[i]<mean_value):\n",
    "            lst[i]=1\n",
    "        elif(lst[i]>mean_value and lst[i]<1.5*mean_value):\n",
    "            lst[i]=2\n",
    "        elif(lst[i]>=1.5*mean_value):\n",
    "            lst[i]=3\n",
    "    lst=np.array(lst,dtype='int')\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "data=load_iris()\n",
    "panda_data=pd.DataFrame(data.data)\n",
    "print(data.target)\n",
    "length=len(panda_data.columns)\n",
    "for i in range(length):\n",
    "    lst=panda_data[i]\n",
    "    lst=np.array(lst)\n",
    "    mean_value=np.mean(lst)\n",
    "    panda_data[i]=mapper(lst,mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    37\n",
       "1    35\n",
       "0    33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(panda_data,data.target,test_size=0.3,random_state=2)\n",
    "X_train=pd.DataFrame(X_train)\n",
    "X_train.index=np.arange(len(X_train))\n",
    "X_test.index=np.arange(len(X_test))\n",
    "Y_train=pd.Series(Y_train)\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns=list('abcd')\n",
    "X_test.columns=list('abcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'a': {1: 33, 2: 0},\n",
       "  'b': {1: 4, 2: 29},\n",
       "  'c': {1: 33, 2: 0, 3: 0},\n",
       "  'd': {0: 23, 1: 10, 2: 0, 3: 0},\n",
       "  'total_class': 33},\n",
       " 1: {'a': {1: 17, 2: 18},\n",
       "  'b': {1: 28, 2: 7},\n",
       "  'c': {1: 5, 2: 30, 3: 0},\n",
       "  'd': {0: 0, 1: 9, 2: 25, 3: 1},\n",
       "  'total_class': 35},\n",
       " 2: {'a': {1: 5, 2: 32},\n",
       "  'b': {1: 26, 2: 11},\n",
       "  'c': {1: 0, 2: 24, 3: 13},\n",
       "  'd': {0: 0, 1: 0, 2: 4, 3: 33},\n",
       "  'total_class': 37},\n",
       " 'total_training': 105}"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary=fit(X_train,Y_train)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  0  0]\n",
      " [ 1 14  0]\n",
      " [ 0  0 13]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        18\n",
      "          1       0.93      1.00      0.97        14\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans=predict(dictionary,X_test)\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(Y_test,ans))\n",
    "print(classification_report(ans,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
